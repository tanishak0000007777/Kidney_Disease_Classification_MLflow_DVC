{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T11:19:36.266273Z",
     "start_time": "2025-11-11T11:19:36.253235Z"
    }
   },
   "cell_type": "code",
   "source": "import os",
   "id": "12c549d8873238ae",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T11:19:37.838489Z",
     "start_time": "2025-11-11T11:19:37.809326Z"
    }
   },
   "cell_type": "code",
   "source": "%pwd",
   "id": "142107ac3ce030d2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\91781\\\\PycharmProjects\\\\Kideney_Disease_Classification_MLflow_DVC\\\\research'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T11:19:40.185803Z",
     "start_time": "2025-11-11T11:19:40.172168Z"
    }
   },
   "cell_type": "code",
   "source": "os.chdir(\"../\")",
   "id": "b22aae1ea5b5544e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T11:19:41.975836Z",
     "start_time": "2025-11-11T11:19:41.964013Z"
    }
   },
   "cell_type": "code",
   "source": "%pwd",
   "id": "6f04e71929a10ac0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\91781\\\\PycharmProjects\\\\Kideney_Disease_Classification_MLflow_DVC'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T08:37:17.335540Z",
     "start_time": "2025-11-11T08:37:17.323337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ],
   "id": "8602f9c096312bbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91781\\anaconda3\\envs\\kidney\\python.exe\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T11:23:34.016786Z",
     "start_time": "2025-11-11T11:23:27.951621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='tanishak0000007777',\n",
    "             repo_name='Kidney_Disease_Classification_MLflow_DVC',\n",
    "             mlflow=True)\n",
    "\n",
    "import mlflow\n",
    "print(\"‚úÖ Connected to DagsHub successfully!\")\n"
   ],
   "id": "887c7cfc6f7ffead",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accessing as tanishak0000007777\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as tanishak0000007777\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Initialized MLflow to track repo \u001B[32m\"tanishak0000007777/Kidney_Disease_Classification_MLflow_DVC\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"tanishak0000007777/Kidney_Disease_Classification_MLflow_DVC\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Repository tanishak0000007777/Kidney_Disease_Classification_MLflow_DVC initialized!\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository tanishak0000007777/Kidney_Disease_Classification_MLflow_DVC initialized!\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to DagsHub successfully!\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T10:04:19.212096Z",
     "start_time": "2025-11-11T10:04:10.583229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"GPUs:\", tf.config.list_physical_devices('GPU'))\n",
    "\n"
   ],
   "id": "c74e709f0cbfa374",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.20.0\n",
      "Num GPUs Available: 0\n",
      "GPUs: []\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T11:19:30.921454Z",
     "start_time": "2025-11-11T11:19:30.895797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n"
   ],
   "id": "533b96897244e19b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T11:19:54.409472Z",
     "start_time": "2025-11-11T11:19:53.388241Z"
    }
   },
   "cell_type": "code",
   "source": "model=tf.keras.models.load_model(\"artifacts/training/model.h5\")",
   "id": "8c8e04f10898e04f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T11:52:08.521558Z",
     "start_time": "2025-11-11T11:52:08.388684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class EvaluationConfig:\n",
    "    path_of_model: Path\n",
    "    training_data: Path\n",
    "    all_params: dict\n",
    "    mlflow_uri: str\n",
    "    params_image_size: list\n",
    "    params_batch_size: int"
   ],
   "id": "546529839571823b",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T11:52:11.352682Z",
     "start_time": "2025-11-11T11:52:11.339571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.cnnClassifier.constants import *\n",
    "from src.cnnClassifier.utils.common import read_yaml, create_directories, save_json"
   ],
   "id": "a965e1bab310c746",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T11:52:12.610325Z",
     "start_time": "2025-11-11T11:52:12.582464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath=CONFIG_FILE_PATH, params_filepath=PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_evaluation_config(self) -> EvaluationConfig:\n",
    "        eval_config = EvaluationConfig(\n",
    "            path_of_model=Path(\"artifacts/training/model.h5\"),\n",
    "            training_data=Path(\"artifacts/data_ingestion/kdc_dataset\"),\n",
    "            mlflow_uri=\"https://dagshub.com/tanishak0000007777/Kidney_Disease_Classification_MLflow_DVC.mlflow\",\n",
    "            all_params=self.params,\n",
    "            params_image_size=self.params.IMAGE_SIZE,\n",
    "            params_batch_size=self.params.BATCH_SIZE\n",
    "        )\n",
    "        return eval_config"
   ],
   "id": "1e58cf8158fe6611",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T11:22:17.425328Z",
     "start_time": "2025-11-11T11:22:15.790876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from urllib.parse import urlparse"
   ],
   "id": "4d6e723d13f5dccc",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T12:10:37.883100Z",
     "start_time": "2025-11-11T12:10:37.688255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Evaluation:\n",
    "    def __init__(self, config: EvaluationConfig):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "        self.valid_generator = None\n",
    "        self.score = None\n",
    "\n",
    "    # Create validation data generator\n",
    "    def _valid_generator(self):\n",
    "        datagenerator_kwargs = dict(rescale=1.0 / 255, validation_split=0.30)\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size=self.config.params_image_size[:-1],\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            interpolation=\"bilinear\"\n",
    "        )\n",
    "\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(**datagenerator_kwargs)\n",
    "        self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"validation\",\n",
    "            shuffle=False,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "    # Load saved model\n",
    "    @staticmethod\n",
    "    def load_model(path: Path) -> tf.keras.Model:\n",
    "        return tf.keras.models.load_model(path)\n",
    "\n",
    "    # Evaluate the model\n",
    "    def evaluation(self):\n",
    "        print(\"üîç Loading model...\")\n",
    "        self.model = self.load_model(self.config.path_of_model)\n",
    "        print(\"‚úÖ Model loaded successfully.\")\n",
    "\n",
    "        print(\"üì¶ Preparing validation data...\")\n",
    "        self._valid_generator()\n",
    "\n",
    "        print(\"üß™ Evaluating model...\")\n",
    "        self.score = self.model.evaluate(self.valid_generator)\n",
    "        print(f\"‚úÖ Evaluation complete ‚Äî Loss: {self.score[0]:.4f}, Accuracy: {self.score[1]:.4f}\")\n",
    "\n",
    "        self.save_score()\n",
    "\n",
    "    # Save scores locally\n",
    "    def save_score(self):\n",
    "        scores = {\"loss\": float(self.score[0]), \"accuracy\": float(self.score[1])}\n",
    "        save_json(path=Path(\"scores.json\"), data=scores)\n",
    "        print(\"üíæ Scores saved to scores.json\")\n",
    "\n",
    "    # Log results to DagsHub (MLflow)\n",
    "    def log_into_mlflow(self):\n",
    "        print(\"üöÄ Logging metrics & model to MLflow (DagsHub)...\")\n",
    "        mlflow.set_tracking_uri(self.config.mlflow_uri)\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "        # ‚úÖ Create a custom run name (e.g. \"VGG16 Evaluation Run\")\n",
    "        with mlflow.start_run(run_name=\"VGG16 Evaluation Run\"):\n",
    "            # Log parameters and metrics\n",
    "            mlflow.log_params(self.config.all_params)\n",
    "            mlflow.log_metrics({\n",
    "                \"loss\": self.score[0],\n",
    "                \"accuracy\": self.score[1]\n",
    "            })\n",
    "\n",
    "            # ‚úÖ Save model locally first\n",
    "            import os\n",
    "            local_model_path = \"artifacts/evaluated_model\"\n",
    "            os.makedirs(local_model_path, exist_ok=True)\n",
    "            model_save_path = os.path.join(local_model_path, \"VGG16Model.h5\")\n",
    "            self.model.save(model_save_path)\n",
    "\n",
    "            # ‚úÖ Log as artifact (model)\n",
    "            mlflow.log_artifact(model_save_path, artifact_path=\"VGG16Model\")\n",
    "\n",
    "            # ‚úÖ Add custom tags for better organization\n",
    "            mlflow.set_tag(\"model_name\", \"VGG16\")\n",
    "            mlflow.set_tag(\"phase\", \"evaluation\")\n",
    "            mlflow.set_tag(\"framework\", \"TensorFlow\")\n",
    "\n",
    "        print(\"üéØ Metrics & 'VGG16Model' successfully logged to DagsHub!\")\n",
    "\n"
   ],
   "id": "5febdaf31ae605f",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-11T12:03:52.585843Z",
     "start_time": "2025-11-11T12:00:01.714343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        config = ConfigurationManager()\n",
    "        eval_config = config.get_evaluation_config()\n",
    "        evaluation = Evaluation(eval_config)\n",
    "\n",
    "        evaluation.evaluation()\n",
    "        evaluation.log_into_mlflow()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during evaluation: {e}\")\n",
    "        raise e"
   ],
   "id": "a15fc3f9460208c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded successfully.\n",
      "üì¶ Preparing validation data...\n",
      "Found 2207 images belonging to 2 classes.\n",
      "üß™ Evaluating model...\n",
      "\u001B[1m138/138\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m157s\u001B[0m 1s/step - accuracy: 0.6760 - loss: 2.0119\n",
      "‚úÖ Evaluation complete ‚Äî Loss: 2.0119, Accuracy: 0.6760\n",
      "üíæ Scores saved to scores.json\n",
      "üöÄ Logging metrics to MLflow (DagsHub)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run blushing-chimp-196 at: https://dagshub.com/tanishak0000007777/Kidney_Disease_Classification_MLflow_DVC.mlflow/#/experiments/0/runs/13e023735d434324a4e3e14248803732\n",
      "üß™ View experiment at: https://dagshub.com/tanishak0000007777/Kidney_Disease_Classification_MLflow_DVC.mlflow/#/experiments/0\n",
      "üéØ Metrics & model successfully logged to DagsHub!\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "afb2171d5224fca3"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
